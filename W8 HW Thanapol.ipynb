{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4cc7cc4",
   "metadata": {},
   "source": [
    "#### Question 1:\n",
    "a.) Decision Tree is a tree-like model visually displaying decisions and their potential outcomes. The tree is used to address categorization problems, key Characteristics of Classification Problems such as target variable (e.g., \"Yes/No,\" \"Low/Medium/High\"), Data and Objective. Some examples of real-world applications where this might be particularly useful is Healthcare where decision tree is used to classify patients as \"diseased\" or \"healthy\" based on medical test results and symptoms and predict the likelihood of developing a risk condition.\n",
    "\n",
    "b.) A Classification Decision Tree predicts by splitting data into subsets based on decision rules and assigning a class label at the leaf nodes. It works by categorize the outputs, focusing on rules that maximize separation . In contrast, Multiple Linear Regression predicts a continuous numerical value by modeling best fit the relationship between features and the target variable as a linear equation, minimizing the error between actual and predicted values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2d9669",
   "metadata": {},
   "source": [
    "#### Question 2:\n",
    "\n",
    "here are some real world scenarios where each of these metrics would be useful:\n",
    "\n",
    "1.Accuracy: can be useful in spam email detection when both false positives (non-spam marked as spam) and false negatives (spam missed) are equally important which use to seperate the spam mails from other mails.\n",
    "\n",
    "2.Sensitivity: is important to recheck the data where it can be use in critical in disease screening, e.g., identifying cancer patients, where missing a positive case can have severe consequences.\n",
    "\n",
    "3.Specificity: Important in fraud detection to minimize false alarms, ensuring legitimate transactions aren't flagged as fraud.\n",
    "\n",
    "4.Precision: Essential in product recommendation systems to ensure that suggested items are highly relevant, reducing irrelevant recommendations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799393aa",
   "metadata": {},
   "source": [
    "### Chatbot summarizes Question 1-2\n",
    "\n",
    "Sure! Here's a summary of our conversation:  \n",
    "\n",
    "We discussed the purpose of **Classification Decision Trees**, highlighting how they address categorization problems and provided real-world applications such as disease diagnosis, fraud detection, and customer segmentation. We then compared how **Classification Decision Trees** predict categorical outcomes through decision rules, while **Multiple Linear Regression** predicts continuous outcomes using a linear equation. Finally, we explored scenarios where decision tree evaluation metrics are particularly useful: **accuracy** for balanced importance (e.g., spam detection), **sensitivity** for critical cases (e.g., disease screening), **specificity** for minimizing false positives (e.g., fraud detection), and **precision** for ensuring relevance (e.g., product recommendations).  \n",
    "\n",
    "Let me know if you need further clarification or edits!\n",
    "https://chatgpt.com/share/6740022b-ef7c-800e-a7a2-79eb10a501a7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec80fcd",
   "metadata": {},
   "source": [
    "#### Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07d299d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, recall_score, make_scorer\n",
    "import graphviz as gv\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pointOfive/STA130_F23/main/Data/amazonbooks.csv\"\n",
    "ab = pd.read_csv(url, encoding=\"ISO-8859-1\")\n",
    "# create `ab_reduced_noNaN` based on the specs above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b47fb1e",
   "metadata": {},
   "source": [
    "#### Question 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ef2194b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/thanapollorcharoensin/Downloads/amazonbooks.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load the dataset from the local path\u001b[39;00m\n\u001b[1;32m     11\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/thanapollorcharoensin/Downloads/amazonbooks.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mISO-8859-1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Check the first few rows to understand the structure\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/thanapollorcharoensin/Downloads/amazonbooks.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the local path\n",
    "file_path = '/Users/thanapollorcharoensin/Downloads/amazonbooks.csv'\n",
    "df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Check the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Assuming 'target_column' is the column you're predicting, adjust as needed\n",
    "X = df.drop('target_column', axis=1)  # Drop the target column\n",
    "y = df['target_column']  # Replace with your actual target column name\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the DecisionTreeClassifier\n",
    "clf2 = DecisionTreeClassifier(random_state=42)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances and feature names\n",
    "importances = clf2.feature_importances_\n",
    "feature_names = clf2.feature_names_in_\n",
    "\n",
    "# Sort the feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(importances)), importances[indices], align='center')\n",
    "plt.yticks(range(len(importances)), feature_names[indices])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importances in Decision Tree Classifier')\n",
    "plt.gca().invert_yaxis()  # Reverse the order to have the most important feature at the top\n",
    "plt.show()\n",
    "\n",
    "# Report the most important feature\n",
    "most_important_feature = feature_names[indices[0]]\n",
    "print(f\"The most important feature is: {most_important_feature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b949c5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists('/Users/thanapollorcharoensin/Downloads/amazonbooks (1).csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b42333",
   "metadata": {},
   "source": [
    "### ***I have tried to use the url provided in the hw but turn out it couldn't load and access i tried help the help of the chatbot but still cant figure it out when i tried to download the csv and provided the file path to the csv file i download it said that the path doesn't exit i tried to ask chatbot but still dont know why this is happen, resulting in myself cant answer the question that's all related to the csv code\n",
    "\n",
    "chatbot summary:\n",
    "\n",
    "Here’s a summary of our conversation:\n",
    "\n",
    "You initially asked how to visualize feature importances in a scikit-learn decision tree. I provided code for that, but you encountered errors like `NotFittedError` and `NameError` because the model wasn’t trained, or the data wasn’t defined. You then tried to load data from a URL, but faced issues with encoding and path errors. I suggested using a different encoding and downloading the file manually. Finally, you asked for a summary of our conversation.\n",
    "https://chatgpt.com/share/67400cfb-282c-800e-9ce8-1f416a7abd6e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed749a",
   "metadata": {},
   "source": [
    "#### Question 7:\n",
    "\n",
    "The first confusion matrix use only the List Price feature to predit, therefore, it might not fully capture the patterns necessary to distinguish between the two outcome labels (\"Paper\" and \"Hard\"). While the second confusion matrix incorporates multiple features, including 'NumPages','Thick','List Price' making it provide a better and more suitable of of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11b5a0",
   "metadata": {},
   "source": [
    "### Chatbot summarizes Question 7\n",
    "\n",
    "Certainly! Here's a summary of our conversation:\n",
    "\n",
    "- We discussed the differences between two confusion matrices related to a classification model's predictions. The first confusion matrix uses only one feature (`List Price`), while the second matrix incorporates multiple features (`NumPages`, `Thick`, `List Price`), improving the model's accuracy.\n",
    "- The second model, which uses more features, provides a better understanding of the outcomes, leading to more accurate predictions. We also compared these matrices to two other models (clf and clf2), which are better due to their use of richer, more comprehensive data.\n",
    "\n",
    "Let me know if you'd like more details on any part!\n",
    "https://chatgpt.com/share/6740067d-e338-800e-aa9d-0f6f504d126e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84299b75",
   "metadata": {},
   "source": [
    "#### Question 8:\n",
    "\n",
    "To visualize feature importances for a scikit-learn classification decision tree (clf2), we can use a bar chart, which will allow you to see the relative importance of each feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc01101",
   "metadata": {},
   "source": [
    "#### Question 9:\n",
    "\n",
    "In linear regression, the coefficients represent the magnitude and direction of the relationship between each independent variable and dependent variable. In a decision tree, feature importance is a measure of how valuable each feature is in making predictions by using feature values splits outcome to different branches like tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea207e",
   "metadata": {},
   "source": [
    "### Chatbot summarizes Question 9\n",
    "\n",
    "Here’s a summary of our conversation:\n",
    "\n",
    "- **Linear Regression vs. Decision Trees**: \n",
    "  - In linear regression, the **coefficients** represent the direct relationship between each feature and the target variable, showing how much the target changes with each unit change in the feature, assuming other features stay constant.\n",
    "  - In decision trees, **feature importances** show how valuable each feature is in making predictions, based on how much it reduces impurity (like Gini impurity or entropy for classification, and variance for regression). These importances reflect which features contribute most to the model's decision-making process.\n",
    "\n",
    "- **Decision Tree Splitting**: \n",
    "  - Decision trees use criteria such as **Gini Impurity**, **Entropy**, and **Variance Reduction** to decide where to split the data. For classification, they use Gini Impurity or Entropy to find the best splits that minimize class uncertainty, while for regression, they use variance reduction to minimize the spread of values in the resulting subgroups.\n",
    "\n",
    "Let me know if you'd like to explore any of these points further!\n",
    "https://chatgpt.com/share/67400e59-acf8-800e-9910-083e8e38060b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ee989f",
   "metadata": {},
   "source": [
    "Question 10:i havn't review wiki textbook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
